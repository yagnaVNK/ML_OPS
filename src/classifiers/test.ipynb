{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Initializing ZenML repository at e:\\GitHub\\ML_OPS\\src\\classifiers.\n",
      "\n",
      "⠋ Initializing ZenML repository at e:\\GitHub\\ML_OPS\\src\\classifiers.\n",
      "\u001b[1;35mSetting the repo active workspace to 'default'.\u001b[0m\n",
      "\u001b[33mSetting the repo active stack to default.\u001b[0m\n",
      "\n",
      "ZenML repository initialized at e:\\GitHub\\ML_OPS\\src\\classifiers.\n",
      "⠹ Initializing ZenML repository at e:\\GitHub\\ML_OPS\\src\\classifiers.\n",
      "\n",
      "⠹ Initializing ZenML repository at e:\\GitHub\\ML_OPS\\src\\classifiers.\n",
      "\n",
      "\n",
      "The local active stack was initialized to 'default'. This local configuration \n",
      "will only take effect when you're running ZenML from the initialized repository\n",
      "root, or from a subdirectory. For more information on repositories and \n",
      "configurations, please visit \n",
      "https://docs.zenml.io/user-guide/starter-guide/understand-stacks.\n"
     ]
    }
   ],
   "source": [
    "!zenml init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.client import Client\n",
    "\n",
    "artifact = Client().get_artifact_version('8a2d6bec-a9ea-4cae-8ca1-e1eb1442a60c')\n",
    "loaded_artifact = artifact.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95.83333333333334, 66.83333333333333, 65.16666666666666, 63.66666666666667]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(\"best_HAE.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict([(34,\n",
       "               <function torch.distributed._shard.sharded_tensor.state_dict_hook(module, destination, prefix, local_metadata)>)]),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict([(35,\n",
       "               <torch.nn.modules.module._WrappedHook at 0x17b9c009ae0>)]),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('encoder',\n",
       "               Encoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(2, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (3): Mish()\n",
       "                   (4): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "                   (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                 )\n",
       "               )),\n",
       "              ('decoder',\n",
       "               Decoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): Upsample()\n",
       "                   (3): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (4): Mish()\n",
       "                   (5): Conv1d(8, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (6): Tanh()\n",
       "                 )\n",
       "               )),\n",
       "              ('normalize', GlobalNormalization1())]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cpu'),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_current_fx_name': None,\n",
       " '_automatic_optimization': False,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"Cos_coeff\":      0.7\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"codebook_init\":  normal\n",
       " \"cos_reset\":      1\n",
       " \"dec_hidden_dim\": 16\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 16\n",
       " \"input_feat_dim\": 2\n",
       " \"layer\":          0\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 0\n",
       " \"output_dir\":     CodeCos2R,\n",
       " '_hparams_initial': \"Cos_coeff\":      0.7\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"codebook_init\":  normal\n",
       " \"cos_reset\":      1\n",
       " \"dec_hidden_dim\": 16\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 16\n",
       " \"input_feat_dim\": 2\n",
       " \"layer\":          0\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 0\n",
       " \"output_dir\":     CodeCos2R,\n",
       " 'prev_model': None,\n",
       " 'out_feat_dim': 2,\n",
       " 'codebook_dim': 64,\n",
       " 'lr': 0.0004,\n",
       " 'decay': True,\n",
       " 'clip_grads': False,\n",
       " 'layer': 0,\n",
       " 'Cos_coeff': tensor(0.7000),\n",
       " 'cos_reset': 1,\n",
       " 'create_output': True,\n",
       " 'output_dir': 'CodeCos2R',\n",
       " '_forward_hooks_always_called': OrderedDict()}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
