{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing ZenML repository at path 'e:\\GitHub\\ML_OPS'.\n",
      "⠋ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\n",
      "⠋ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!zenml init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "\n",
    "\n",
    "class ExampleNetwork(LightningModule):\n",
    "    def __init__(self, model, data_loader, val_data_loader,experimentName):\n",
    "        super(ExampleNetwork, self).__init__()\n",
    "        self.mdl: torch.nn.Module = model\n",
    "        self.data_loader: DataLoader = data_loader\n",
    "        self.val_data_loader: DataLoader = val_data_loader\n",
    "\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 16\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.mdl(x.float())\n",
    "\n",
    "    def predict(self, x: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x.float())\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data_loader\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_nb: int):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = F.cross_entropy(self(x.float()), y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_nb: int):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = F.cross_entropy(self(x.float()), y)\n",
    "        return loss\n",
    "\n",
    "    def on_fit_end(self):\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchsig.models.iq_models.efficientnet.efficientnet import efficientnet_b4\n",
    "\n",
    "\n",
    "model = torch.load(\"src/classifiers/best_hae.pt\")\n",
    "\n",
    "classes = [\"4ask\",\"8pam\",\"16psk\",\"32qam_cross\",\"2fsk\",\"ofdm-256\"]\n",
    "model_eff = efficientnet_b4(\n",
    "        pretrained=False,\n",
    "        num_classes=len(classes)\n",
    "    )\n",
    "\n",
    "example_model = ExampleNetwork(model_eff,None,None,None)\n",
    "example_model = example_model.float().to(\"cuda\")\n",
    "\n",
    "example_model.load_state_dict(torch.load(\"src/classifiers/10epochs_classifier.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchsig\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchsig.transforms as ST\n",
    "from torchsig.utils.cm_plotter import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_samples = 1024\n",
    "samples_per_class = 1000\n",
    "batch_size = 32\n",
    "Hae_epochs = 30\n",
    "Hqa_epochs = 30\n",
    "classifier_epochs = 10\n",
    "trainbool = True\n",
    "eff_net_PATH = f\"./src/classifiers/{classifier_epochs}epochs_classifier.pt\"\n",
    "device = \"cuda\"\n",
    "layers = 5\n",
    "input_feature_dim = 2\n",
    "enc_hidden_sizes = [16, 16, 32, 64, 128, 256]\n",
    "dec_hidden_sizes = [16, 64, 256, 512, 1024, 2048]\n",
    "codebook_slots = 64\n",
    "codeword_dim = 64\n",
    "codebook_init = \"normal\"\n",
    "batch_norm = 1\n",
    "reset_choice = 1\n",
    "num_res_blocks = 0\n",
    "cos_reset = 1\n",
    "compress = 2\n",
    "hae_lr = 4e-4\n",
    "hqa_lr = 4e-4\n",
    "hae_Cos_coeff = 0.001\n",
    "hqa_Cos_coeff = 0.7\n",
    "KL_coeff = 0.1\n",
    "CL_coeff = 0.005\n",
    "\n",
    "accuracies = []\n",
    "num_recons = 1\n",
    "num_classes = len(classes)\n",
    "layers = len(model)\n",
    "data_transform = ST.Compose([\n",
    "        ST.ComplexTo2D(),\n",
    "    ])\n",
    "ds_test = ModulationsDataset(\n",
    "        classes = classes,\n",
    "        use_class_idx = True,\n",
    "        level=0,\n",
    "        num_iq_samples=iq_samples,\n",
    "        num_samples=int(len(classes)*samples_per_class)/10,\n",
    "        include_snr=False,\n",
    "        transform = data_transform\n",
    "    )\n",
    "\n",
    "num_test_examples = len(ds_test)\n",
    "\n",
    "for j in range(layers):\n",
    "    for k in range(num_recons): \n",
    "        y_raw_preds = np.empty((num_test_examples, num_classes))\n",
    "        y_preds = np.zeros((num_test_examples,))\n",
    "        y_true = np.zeros((num_test_examples,))\n",
    "        hae = model[j]\n",
    "        hae = hae.float().to(device)\n",
    "        hae.eval()\n",
    "        example_model.to(device).eval()\n",
    "        for i in tqdm(range(0, num_test_examples)):\n",
    "            # Retrieve data\n",
    "            idx = i  # Use index if evaluating over full dataset\n",
    "            \n",
    "            data, label = ds_test[idx]\n",
    "            #test_x = hae.reconstruct(data)\n",
    "            test_x = hae.reconstruct(torch.from_numpy(np.expand_dims(data, 0)).float().to(device))\n",
    "            #test_x = torch.from_numpy(np.expand_dims(data, 0)).float().to(device)\n",
    "            # Infer\n",
    "            #test_x = torch.from_numpy(np.expand_dims(test_x, 0)).float().to(device)\n",
    "            pred_tmp = example_model.predict(test_x)\n",
    "            pred_tmp = pred_tmp.cpu().numpy() if torch.cuda.is_available() else pred_tmp\n",
    "            # Argmax\n",
    "            y_preds[i] = np.argmax(pred_tmp)\n",
    "            # Store label\n",
    "            y_true[i] = label\n",
    "    \n",
    "    \n",
    "        acc = np.sum(np.asarray(y_preds) == np.asarray(y_true)) / len(y_true)\n",
    "        plot_confusion_matrix(\n",
    "            y_true,\n",
    "            y_preds,\n",
    "            classes=classes,\n",
    "            normalize=True,\n",
    "            title=\"Example Modulations Confusion Matrix\\nTotal Accuracy: {:.2f}%\".format(\n",
    "                acc * 100\n",
    "            ),\n",
    "            text=False,\n",
    "            rotate_x_text=60,\n",
    "            figsize=(10, 10),\n",
    "        )\n",
    "        confusionMatrix_save_path = f\"./vis/confusion_matrix_layer_{j+1}_recon_{k+1}.png\"\n",
    "        #plt.savefig(confusionMatrix_save_path)\n",
    "        print(f\"Layer {j+1}\\nClassification Report: \\nAccuracy {acc*100}\")\n",
    "        print(classification_report(y_true, y_preds))\n",
    "        matplotlib.pyplot.close()\n",
    "        accuracies.append(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(model[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zenml.client import Client\n",
    "\n",
    "artifact = Client().get_artifact_version('1f20bebb-033a-4f60-9dff-0fda94bb9eb4')\n",
    "loaded_artifact = artifact.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAE(\n",
       "  (prev_model): HAE(\n",
       "    (prev_model): HAE(\n",
       "      (prev_model): HAE(\n",
       "        (encoder): Encoder(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv1d(2, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "            (1): Mish()\n",
       "            (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (3): Mish()\n",
       "            (4): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (decoder): Decoder(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Mish()\n",
       "            (2): Upsample()\n",
       "            (3): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (4): Mish()\n",
       "            (5): Conv1d(8, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (6): Tanh()\n",
       "          )\n",
       "        )\n",
       "        (normalize): GlobalNormalization1()\n",
       "      )\n",
       "      (encoder): Encoder(\n",
       "        (blocks): Sequential(\n",
       "          (0): Conv1d(64, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (1): Mish()\n",
       "          (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (3): Mish()\n",
       "          (4): ResBlock(\n",
       "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (5): ResBlock(\n",
       "            (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (6): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (decoder): Decoder(\n",
       "        (blocks): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Mish()\n",
       "          (2): ResBlock(\n",
       "            (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (3): ResBlock(\n",
       "            (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (4): Upsample()\n",
       "          (5): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (6): Mish()\n",
       "          (7): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (normalize): GlobalNormalization1()\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(64, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): Mish()\n",
       "        (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (3): Mish()\n",
       "        (4): ResBlock(\n",
       "          (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (5): ResBlock(\n",
       "          (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (6): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Mish()\n",
       "        (2): ResBlock(\n",
       "          (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (4): Upsample()\n",
       "        (5): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (6): Mish()\n",
       "        (7): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (normalize): GlobalNormalization1()\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (blocks): Sequential(\n",
       "      (0): Conv1d(64, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): Mish()\n",
       "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (3): Mish()\n",
       "      (4): ResBlock(\n",
       "        (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (6): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (blocks): Sequential(\n",
       "      (0): Conv1d(64, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): Mish()\n",
       "      (2): ResBlock(\n",
       "        (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (4): Upsample()\n",
       "      (5): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (6): Mish()\n",
       "      (7): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       "  (normalize): GlobalNormalization1()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_artifact[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 8, 512]              56\n",
      "              Mish-2               [-1, 8, 512]               0\n",
      "            Conv1d-3              [-1, 16, 512]             400\n",
      "              Mish-4              [-1, 16, 512]               0\n",
      "            Conv1d-5              [-1, 64, 512]           1,088\n",
      "       BatchNorm1d-6              [-1, 64, 512]             128\n",
      "           Encoder-7              [-1, 64, 512]               0\n",
      "GlobalNormalization1-8              [-1, 64, 512]               0\n",
      "            Conv1d-9               [-1, 8, 256]           1,544\n",
      "             Mish-10               [-1, 8, 256]               0\n",
      "           Conv1d-11              [-1, 16, 256]             400\n",
      "             Mish-12              [-1, 16, 256]               0\n",
      "           Conv1d-13               [-1, 8, 256]             392\n",
      "           Conv1d-14              [-1, 16, 256]             400\n",
      "         ResBlock-15              [-1, 16, 256]               0\n",
      "           Conv1d-16               [-1, 8, 256]             392\n",
      "           Conv1d-17              [-1, 16, 256]             400\n",
      "         ResBlock-18              [-1, 16, 256]               0\n",
      "           Conv1d-19              [-1, 64, 256]           1,088\n",
      "      BatchNorm1d-20              [-1, 64, 256]             128\n",
      "          Encoder-21              [-1, 64, 256]               0\n",
      "GlobalNormalization1-22              [-1, 64, 256]               0\n",
      "           Conv1d-23              [-1, 16, 128]           3,088\n",
      "             Mish-24              [-1, 16, 128]               0\n",
      "           Conv1d-25              [-1, 32, 128]           1,568\n",
      "             Mish-26              [-1, 32, 128]               0\n",
      "           Conv1d-27              [-1, 16, 128]           1,552\n",
      "           Conv1d-28              [-1, 32, 128]           1,568\n",
      "         ResBlock-29              [-1, 32, 128]               0\n",
      "           Conv1d-30              [-1, 16, 128]           1,552\n",
      "           Conv1d-31              [-1, 32, 128]           1,568\n",
      "         ResBlock-32              [-1, 32, 128]               0\n",
      "           Conv1d-33              [-1, 64, 128]           2,112\n",
      "      BatchNorm1d-34              [-1, 64, 128]             128\n",
      "          Encoder-35              [-1, 64, 128]               0\n",
      "GlobalNormalization1-36              [-1, 64, 128]               0\n",
      "           Conv1d-37               [-1, 32, 64]           6,176\n",
      "             Mish-38               [-1, 32, 64]               0\n",
      "           Conv1d-39               [-1, 64, 64]           6,208\n",
      "             Mish-40               [-1, 64, 64]               0\n",
      "           Conv1d-41               [-1, 32, 64]           6,176\n",
      "           Conv1d-42               [-1, 64, 64]           6,208\n",
      "         ResBlock-43               [-1, 64, 64]               0\n",
      "           Conv1d-44               [-1, 32, 64]           6,176\n",
      "           Conv1d-45               [-1, 64, 64]           6,208\n",
      "         ResBlock-46               [-1, 64, 64]               0\n",
      "           Conv1d-47               [-1, 64, 64]           4,160\n",
      "      BatchNorm1d-48               [-1, 64, 64]             128\n",
      "          Encoder-49               [-1, 64, 64]               0\n",
      "           Conv1d-50              [-1, 512, 64]          98,816\n",
      "             Mish-51              [-1, 512, 64]               0\n",
      "           Conv1d-52              [-1, 256, 64]         393,472\n",
      "           Conv1d-53              [-1, 512, 64]         393,728\n",
      "         ResBlock-54              [-1, 512, 64]               0\n",
      "           Conv1d-55              [-1, 256, 64]         393,472\n",
      "           Conv1d-56              [-1, 512, 64]         393,728\n",
      "         ResBlock-57              [-1, 512, 64]               0\n",
      "         Upsample-58             [-1, 512, 128]               0\n",
      "           Conv1d-59             [-1, 256, 128]         393,472\n",
      "             Mish-60             [-1, 256, 128]               0\n",
      "           Conv1d-61              [-1, 64, 128]          49,216\n",
      "          Decoder-62              [-1, 64, 128]               0\n",
      "================================================================\n",
      "Total params: 2,176,896\n",
      "Trainable params: 2,176,896\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.66\n",
      "Params size (MB): 8.30\n",
      "Estimated Total Size (MB): 13.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(loaded_artifact[3].to('cuda'),(2,1024))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>model = loaded_artifact[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>].to(<span style=\"color: #808000; text-decoration-color: #808000\">'cuda'</span>)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 model.codebook                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e:\\GitHub\\ML_OPS\\virtualEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1688</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1685 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>modules = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__dict__</span>[<span style=\"color: #808000; text-decoration-color: #808000\">'_modules'</span>]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1686 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modules:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1687 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> modules[name]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1688 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"'{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}' object has no attribute '{</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}'\"</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1689 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1690 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__setattr__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, value: Union[Tensor, <span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>]) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1691 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remove_from</span>(*dicts_or_sets):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'HAE'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'codebook'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mmodel = loaded_artifact[\u001b[94m3\u001b[0m].to(\u001b[33m'\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m'\u001b[0m)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 model.codebook                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me:\\GitHub\\ML_OPS\\virtualEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1688\u001b[0m in \u001b[92m__getattr__\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1685 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodules = \u001b[96mself\u001b[0m.\u001b[91m__dict__\u001b[0m[\u001b[33m'\u001b[0m\u001b[33m_modules\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1686 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m modules:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1687 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m modules[name]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1688 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(\u001b[96mself\u001b[0m).\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1689 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1690 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__setattr__\u001b[0m(\u001b[96mself\u001b[0m, name: \u001b[96mstr\u001b[0m, value: Union[Tensor, \u001b[33m'\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m'\u001b[0m]) -> \u001b[94mNone\u001b[0m:             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1691 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mremove_from\u001b[0m(*dicts_or_sets):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'HAE'\u001b[0m object has no attribute \u001b[32m'codebook'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = loaded_artifact[3].to('cuda')\n",
    "\n",
    "model.codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
