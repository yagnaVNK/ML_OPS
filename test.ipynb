{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\n",
      "⠙ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\u001b[1;35mSetting the repo active workspace to 'default'.\u001b[0m\n",
      "\u001b[33mSetting the repo active stack to default.\u001b[0m\n",
      "\n",
      "ZenML repository initialized at e:\\GitHub\\ML_OPS.\n",
      "⠙ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\n",
      "⠙ Initializing ZenML repository at e:\\GitHub\\ML_OPS.\n",
      "\n",
      "\n",
      "The local active stack was initialized to 'default'. This local configuration \n",
      "will only take effect when you're running ZenML from the initialized repository\n",
      "root, or from a subdirectory. For more information on repositories and \n",
      "configurations, please visit \n",
      "https://docs.zenml.io/user-guide/starter-guide/understand-stacks.\n"
     ]
    }
   ],
   "source": [
    "!zenml init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "\n",
    "\n",
    "class ExampleNetwork(LightningModule):\n",
    "    def __init__(self, model, data_loader, val_data_loader,experimentName):\n",
    "        super(ExampleNetwork, self).__init__()\n",
    "        self.mdl: torch.nn.Module = model\n",
    "        self.data_loader: DataLoader = data_loader\n",
    "        self.val_data_loader: DataLoader = val_data_loader\n",
    "\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 16\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.mdl(x.float())\n",
    "\n",
    "    def predict(self, x: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x.float())\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data_loader\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_nb: int):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = F.cross_entropy(self(x.float()), y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_nb: int):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = F.cross_entropy(self(x.float()), y)\n",
    "        return loss\n",
    "\n",
    "    def on_fit_end(self):\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchsig.models.iq_models.efficientnet.efficientnet import efficientnet_b4\n",
    "\n",
    "\n",
    "model = torch.load(\"src/classifiers/best_hae.pt\")\n",
    "\n",
    "classes = [\"4ask\",\"8pam\",\"16psk\",\"32qam_cross\",\"2fsk\",\"ofdm-256\"]\n",
    "model_eff = efficientnet_b4(\n",
    "        pretrained=False,\n",
    "        num_classes=len(classes)\n",
    "    )\n",
    "\n",
    "example_model = ExampleNetwork(model_eff,None,None,None)\n",
    "example_model = example_model.float().to(\"cuda\")\n",
    "\n",
    "example_model.load_state_dict(torch.load(\"src/classifiers/10epochs_classifier.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchsig\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchsig.transforms as ST\n",
    "from torchsig.utils.cm_plotter import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:35<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "Classification Report: \n",
      "Accuracy 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00       100\n",
      "         2.0       1.00      1.00      1.00       100\n",
      "         3.0       1.00      1.00      1.00       100\n",
      "         4.0       1.00      1.00      1.00       100\n",
      "         5.0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:38<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2\n",
      "Classification Report: \n",
      "Accuracy 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00       100\n",
      "         2.0       1.00      1.00      1.00       100\n",
      "         3.0       1.00      1.00      1.00       100\n",
      "         4.0       1.00      1.00      1.00       100\n",
      "         5.0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:40<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3\n",
      "Classification Report: \n",
      "Accuracy 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       100\n",
      "         1.0       1.00      1.00      1.00       100\n",
      "         2.0       1.00      1.00      1.00       100\n",
      "         3.0       1.00      1.00      1.00       100\n",
      "         4.0       1.00      1.00      1.00       100\n",
      "         5.0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:44<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 4\n",
      "Classification Report: \n",
      "Accuracy 93.16666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95       100\n",
      "         1.0       1.00      1.00      1.00       100\n",
      "         2.0       1.00      0.73      0.84       100\n",
      "         3.0       0.78      0.95      0.86       100\n",
      "         4.0       1.00      1.00      1.00       100\n",
      "         5.0       0.88      1.00      0.93       100\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.94      0.93      0.93       600\n",
      "weighted avg       0.94      0.93      0.93       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:46<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 5\n",
      "Classification Report: \n",
      "Accuracy 63.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18       100\n",
      "         1.0       1.00      1.00      1.00       100\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.40      0.68      0.51       100\n",
      "         4.0       1.00      1.00      1.00       100\n",
      "         5.0       0.45      1.00      0.62       100\n",
      "\n",
      "    accuracy                           0.63       600\n",
      "   macro avg       0.64      0.63      0.55       600\n",
      "weighted avg       0.64      0.63      0.55       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\GitHub\\ML_OPS\\virtualEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\GitHub\\ML_OPS\\virtualEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\GitHub\\ML_OPS\\virtualEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "iq_samples = 1024\n",
    "samples_per_class = 1000\n",
    "batch_size = 32\n",
    "Hae_epochs = 30\n",
    "Hqa_epochs = 30\n",
    "classifier_epochs = 10\n",
    "trainbool = True\n",
    "eff_net_PATH = f\"./src/classifiers/{classifier_epochs}epochs_classifier.pt\"\n",
    "device = \"cuda\"\n",
    "layers = 5\n",
    "input_feature_dim = 2\n",
    "enc_hidden_sizes = [16, 16, 32, 64, 128, 256]\n",
    "dec_hidden_sizes = [16, 64, 256, 512, 1024, 2048]\n",
    "codebook_slots = 64\n",
    "codeword_dim = 64\n",
    "codebook_init = \"normal\"\n",
    "batch_norm = 1\n",
    "reset_choice = 1\n",
    "num_res_blocks = 0\n",
    "cos_reset = 1\n",
    "compress = 2\n",
    "hae_lr = 4e-4\n",
    "hqa_lr = 4e-4\n",
    "hae_Cos_coeff = 0.001\n",
    "hqa_Cos_coeff = 0.7\n",
    "KL_coeff = 0.1\n",
    "CL_coeff = 0.005\n",
    "\n",
    "accuracies = []\n",
    "num_recons = 1\n",
    "num_classes = len(classes)\n",
    "layers = len(model)\n",
    "data_transform = ST.Compose([\n",
    "        ST.ComplexTo2D(),\n",
    "    ])\n",
    "ds_test = ModulationsDataset(\n",
    "        classes = classes,\n",
    "        use_class_idx = True,\n",
    "        level=0,\n",
    "        num_iq_samples=iq_samples,\n",
    "        num_samples=int(len(classes)*samples_per_class)/10,\n",
    "        include_snr=False,\n",
    "        transform = data_transform\n",
    "    )\n",
    "\n",
    "num_test_examples = len(ds_test)\n",
    "\n",
    "for j in range(layers):\n",
    "    for k in range(num_recons): \n",
    "        y_raw_preds = np.empty((num_test_examples, num_classes))\n",
    "        y_preds = np.zeros((num_test_examples,))\n",
    "        y_true = np.zeros((num_test_examples,))\n",
    "        hae = model[j]\n",
    "        hae = hae.float().to(device)\n",
    "        hae.eval()\n",
    "        example_model.to(device).eval()\n",
    "        for i in tqdm(range(0, num_test_examples)):\n",
    "            # Retrieve data\n",
    "            idx = i  # Use index if evaluating over full dataset\n",
    "            \n",
    "            data, label = ds_test[idx]\n",
    "            #test_x = hae.reconstruct(data)\n",
    "            test_x = hae.reconstruct(torch.from_numpy(np.expand_dims(data, 0)).float().to(device))\n",
    "            #test_x = torch.from_numpy(np.expand_dims(data, 0)).float().to(device)\n",
    "            # Infer\n",
    "            #test_x = torch.from_numpy(np.expand_dims(test_x, 0)).float().to(device)\n",
    "            pred_tmp = example_model.predict(test_x)\n",
    "            pred_tmp = pred_tmp.cpu().numpy() if torch.cuda.is_available() else pred_tmp\n",
    "            # Argmax\n",
    "            y_preds[i] = np.argmax(pred_tmp)\n",
    "            # Store label\n",
    "            y_true[i] = label\n",
    "    \n",
    "    \n",
    "        acc = np.sum(np.asarray(y_preds) == np.asarray(y_true)) / len(y_true)\n",
    "        plot_confusion_matrix(\n",
    "            y_true,\n",
    "            y_preds,\n",
    "            classes=classes,\n",
    "            normalize=True,\n",
    "            title=\"Example Modulations Confusion Matrix\\nTotal Accuracy: {:.2f}%\".format(\n",
    "                acc * 100\n",
    "            ),\n",
    "            text=False,\n",
    "            rotate_x_text=60,\n",
    "            figsize=(10, 10),\n",
    "        )\n",
    "        confusionMatrix_save_path = f\"./vis/confusion_matrix_layer_{j+1}_recon_{k+1}.png\"\n",
    "        #plt.savefig(confusionMatrix_save_path)\n",
    "        print(f\"Layer {j+1}\\nClassification Report: \\nAccuracy {acc*100}\")\n",
    "        print(classification_report(y_true, y_preds))\n",
    "        matplotlib.pyplot.close()\n",
    "        accuracies.append(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict([(51,\n",
       "               <function torch.distributed._shard.sharded_tensor.state_dict_hook(module, destination, prefix, local_metadata)>)]),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict([(52,\n",
       "               <torch.nn.modules.module._WrappedHook at 0x2514f74bd30>)]),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('prev_model',\n",
       "               HQA(\n",
       "                 (prev_model): HQA(\n",
       "                   (prev_model): HQA(\n",
       "                     (encoder): Encoder(\n",
       "                       (blocks): Sequential(\n",
       "                         (0): Conv1d(2, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                         (1): Mish()\n",
       "                         (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (3): Mish()\n",
       "                         (4): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "                         (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       )\n",
       "                     )\n",
       "                     (decoder): Decoder(\n",
       "                       (blocks): Sequential(\n",
       "                         (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (1): Mish()\n",
       "                         (2): Upsample()\n",
       "                         (3): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (4): Mish()\n",
       "                         (5): Conv1d(8, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (6): Tanh()\n",
       "                       )\n",
       "                     )\n",
       "                     (normalize): GlobalNormalization1()\n",
       "                   )\n",
       "                   (encoder): Encoder(\n",
       "                     (blocks): Sequential(\n",
       "                       (0): Conv1d(64, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                       (1): Mish()\n",
       "                       (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (3): Mish()\n",
       "                       (4): ResBlock(\n",
       "                         (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (5): ResBlock(\n",
       "                         (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (6): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "                       (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                     )\n",
       "                   )\n",
       "                   (decoder): Decoder(\n",
       "                     (blocks): Sequential(\n",
       "                       (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (1): Mish()\n",
       "                       (2): ResBlock(\n",
       "                         (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (3): ResBlock(\n",
       "                         (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (4): Upsample()\n",
       "                       (5): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (6): Mish()\n",
       "                       (7): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                   )\n",
       "                   (normalize): GlobalNormalization1()\n",
       "                 )\n",
       "                 (encoder): Encoder(\n",
       "                   (blocks): Sequential(\n",
       "                     (0): Conv1d(64, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                     (1): Mish()\n",
       "                     (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (3): Mish()\n",
       "                     (4): ResBlock(\n",
       "                       (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (5): ResBlock(\n",
       "                       (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (6): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "                     (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                   )\n",
       "                 )\n",
       "                 (decoder): Decoder(\n",
       "                   (blocks): Sequential(\n",
       "                     (0): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (1): Mish()\n",
       "                     (2): ResBlock(\n",
       "                       (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (3): ResBlock(\n",
       "                       (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (4): Upsample()\n",
       "                     (5): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (6): Mish()\n",
       "                     (7): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                 )\n",
       "                 (normalize): GlobalNormalization1()\n",
       "               )),\n",
       "              ('encoder',\n",
       "               Encoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(64, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (3): Mish()\n",
       "                   (4): ResBlock(\n",
       "                     (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (5): ResBlock(\n",
       "                     (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (6): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                   (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                 )\n",
       "               )),\n",
       "              ('decoder',\n",
       "               Decoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(64, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): ResBlock(\n",
       "                     (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (3): ResBlock(\n",
       "                     (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (4): Upsample()\n",
       "                   (5): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (6): Mish()\n",
       "                   (7): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                 )\n",
       "               )),\n",
       "              ('normalize', GlobalNormalization1())]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cpu'),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_current_fx_name': None,\n",
       " '_automatic_optimization': False,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"Cos_coeff\":      0.7\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"codebook_init\":  normal\n",
       " \"cos_reset\":      1\n",
       " \"dec_hidden_dim\": 512\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 64\n",
       " \"input_feat_dim\": 64\n",
       " \"layer\":          3\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 2\n",
       " \"output_dir\":     CodeCos2R,\n",
       " '_hparams_initial': \"Cos_coeff\":      0.7\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"codebook_init\":  normal\n",
       " \"cos_reset\":      1\n",
       " \"dec_hidden_dim\": 512\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 64\n",
       " \"input_feat_dim\": 64\n",
       " \"layer\":          3\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 2\n",
       " \"output_dir\":     CodeCos2R,\n",
       " 'out_feat_dim': 64,\n",
       " 'codebook_dim': 64,\n",
       " 'lr': 0.0004,\n",
       " 'decay': True,\n",
       " 'clip_grads': False,\n",
       " 'layer': 3,\n",
       " 'Cos_coeff': tensor(0.),\n",
       " 'cos_reset': 1,\n",
       " 'create_output': True,\n",
       " 'output_dir': 'CodeCos2R',\n",
       " '_forward_hooks_always_called': OrderedDict()}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zenml.client import Client\n",
    "\n",
    "artifact = Client().get_artifact_version('1f20bebb-033a-4f60-9dff-0fda94bb9eb4')\n",
    "loaded_artifact = artifact.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('prev_model',\n",
       "               HAE(\n",
       "                 (prev_model): HAE(\n",
       "                   (prev_model): HAE(\n",
       "                     (encoder): Encoder(\n",
       "                       (blocks): Sequential(\n",
       "                         (0): Conv1d(2, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                         (1): Mish()\n",
       "                         (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (3): Mish()\n",
       "                         (4): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "                         (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       )\n",
       "                     )\n",
       "                     (decoder): Decoder(\n",
       "                       (blocks): Sequential(\n",
       "                         (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (1): Mish()\n",
       "                         (2): Upsample()\n",
       "                         (3): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (4): Mish()\n",
       "                         (5): Conv1d(8, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (6): Tanh()\n",
       "                       )\n",
       "                     )\n",
       "                     (normalize): GlobalNormalization1()\n",
       "                   )\n",
       "                   (encoder): Encoder(\n",
       "                     (blocks): Sequential(\n",
       "                       (0): Conv1d(64, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                       (1): Mish()\n",
       "                       (2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (3): Mish()\n",
       "                       (4): ResBlock(\n",
       "                         (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (5): ResBlock(\n",
       "                         (conv_1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (6): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "                       (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                     )\n",
       "                   )\n",
       "                   (decoder): Decoder(\n",
       "                     (blocks): Sequential(\n",
       "                       (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (1): Mish()\n",
       "                       (2): ResBlock(\n",
       "                         (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (3): ResBlock(\n",
       "                         (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                         (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       )\n",
       "                       (4): Upsample()\n",
       "                       (5): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (6): Mish()\n",
       "                       (7): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                   )\n",
       "                   (normalize): GlobalNormalization1()\n",
       "                 )\n",
       "                 (encoder): Encoder(\n",
       "                   (blocks): Sequential(\n",
       "                     (0): Conv1d(64, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                     (1): Mish()\n",
       "                     (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (3): Mish()\n",
       "                     (4): ResBlock(\n",
       "                       (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (5): ResBlock(\n",
       "                       (conv_1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (6): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "                     (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                   )\n",
       "                 )\n",
       "                 (decoder): Decoder(\n",
       "                   (blocks): Sequential(\n",
       "                     (0): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (1): Mish()\n",
       "                     (2): ResBlock(\n",
       "                       (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (3): ResBlock(\n",
       "                       (conv_1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                       (conv_2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     )\n",
       "                     (4): Upsample()\n",
       "                     (5): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (6): Mish()\n",
       "                     (7): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                 )\n",
       "                 (normalize): GlobalNormalization1()\n",
       "               )),\n",
       "              ('encoder',\n",
       "               Encoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(64, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (3): Mish()\n",
       "                   (4): ResBlock(\n",
       "                     (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (5): ResBlock(\n",
       "                     (conv_1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (6): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                   (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                 )\n",
       "               )),\n",
       "              ('decoder',\n",
       "               Decoder(\n",
       "                 (blocks): Sequential(\n",
       "                   (0): Conv1d(64, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (1): Mish()\n",
       "                   (2): ResBlock(\n",
       "                     (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (3): ResBlock(\n",
       "                     (conv_1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                     (conv_2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   )\n",
       "                   (4): Upsample()\n",
       "                   (5): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                   (6): Mish()\n",
       "                   (7): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                 )\n",
       "               )),\n",
       "              ('normalize', GlobalNormalization1())]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cpu'),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_automatic_optimization': False,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"Cos_coeff\":      0.001\n",
       " \"batch_norm\":     1\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"compress\":       2\n",
       " \"cos_reset\":      0\n",
       " \"dec_hidden_dim\": 512\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 64\n",
       " \"experimentName\": training_pipeline\n",
       " \"input_feat_dim\": 64\n",
       " \"layer\":          3\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 2,\n",
       " '_hparams_initial': \"Cos_coeff\":      0.001\n",
       " \"batch_norm\":     1\n",
       " \"clip_grads\":     False\n",
       " \"codebook_dim\":   64\n",
       " \"compress\":       2\n",
       " \"cos_reset\":      0\n",
       " \"dec_hidden_dim\": 512\n",
       " \"decay\":          True\n",
       " \"enc_hidden_dim\": 64\n",
       " \"experimentName\": training_pipeline\n",
       " \"input_feat_dim\": 64\n",
       " \"layer\":          3\n",
       " \"lr\":             0.0004\n",
       " \"num_res_blocks\": 2,\n",
       " 'out_feat_dim': 64,\n",
       " 'codebook_dim': 64,\n",
       " 'lr': 0.0004,\n",
       " 'decay': True,\n",
       " 'clip_grads': False,\n",
       " 'layer': 3,\n",
       " 'Cos_coeff': tensor(0.0010),\n",
       " 'cos_reset': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(loaded_artifact[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
